# H·ªá Th·ªëng Ph√¢n T√≠ch Th·ªã Tr∆∞·ªùng Ch·ª©ng kho√°n Vi·ªát Nam
## Ki·∫øn Tr√∫c T·ªïng Quan

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    DATA INGESTION LAYER                          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  RSS/News APIs  ‚îÇ  Market Data APIs  ‚îÇ  Social Sentiment       ‚îÇ
‚îÇ  (VnEconomy,    ‚îÇ  (FiinGroup,       ‚îÇ  (Facebook, Telegram,   ‚îÇ
‚îÇ   CafeF, HSX)   ‚îÇ   EODHD, VNDirect) ‚îÇ   Zalo Groups)          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ                  ‚îÇ                    ‚îÇ
           ‚ñº                  ‚ñº                    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    n8n WORKFLOW ORCHESTRATOR                     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  ‚Ä¢ Scheduled Scraping (Daily 8:00 AM)                           ‚îÇ
‚îÇ  ‚Ä¢ Data Validation & Deduplication                              ‚îÇ
‚îÇ  ‚Ä¢ Format Normalization                                         ‚îÇ
‚îÇ  ‚Ä¢ Error Handling & Retry Logic                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ
           ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    AWS S3 STORAGE LAYER                          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  /raw-data/          ‚îÇ  /processed/        ‚îÇ  /reports/         ‚îÇ
‚îÇ  - news/             ‚îÇ  - sentiment/       ‚îÇ  - daily/          ‚îÇ
‚îÇ  - market-data/      ‚îÇ  - technical/       ‚îÇ  - weekly/         ‚îÇ
‚îÇ  - social/           ‚îÇ  - combined/        ‚îÇ  - alerts/         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ
           ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    AI AGENT PROCESSING LAYER                     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ
‚îÇ  ‚îÇ Technical Agent ‚îÇ  ‚îÇ Sentiment Agent  ‚îÇ  ‚îÇ Forecast Agent ‚îÇ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ  ‚îÇ                  ‚îÇ  ‚îÇ                ‚îÇ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ RSI, MACD     ‚îÇ  ‚îÇ ‚Ä¢ PhoBERT/GPT-4o ‚îÇ  ‚îÇ ‚Ä¢ Trend Pred.  ‚îÇ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ SMA, EMA      ‚îÇ  ‚îÇ ‚Ä¢ News Analysis  ‚îÇ  ‚îÇ ‚Ä¢ Risk Score   ‚îÇ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Bollinger     ‚îÇ  ‚îÇ ‚Ä¢ Social Mining  ‚îÇ  ‚îÇ ‚Ä¢ Recommend.   ‚îÇ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Volume        ‚îÇ  ‚îÇ ‚Ä¢ Entity Extract ‚îÇ  ‚îÇ ‚Ä¢ Confidence   ‚îÇ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ
‚îÇ           ‚îÇ                    ‚îÇ                      ‚îÇ        ‚îÇ
‚îÇ           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îÇ
‚îÇ                                ‚ñº                                ‚îÇ
‚îÇ                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                     ‚îÇ
‚îÇ                    ‚îÇ   Master Agent       ‚îÇ                     ‚îÇ
‚îÇ                    ‚îÇ   (Orchestrator)     ‚îÇ                     ‚îÇ
‚îÇ                    ‚îÇ                      ‚îÇ                     ‚îÇ
‚îÇ                    ‚îÇ ‚Ä¢ Data Aggregation   ‚îÇ                     ‚îÇ
‚îÇ                    ‚îÇ ‚Ä¢ Cross-validation   ‚îÇ                     ‚îÇ
‚îÇ                    ‚îÇ ‚Ä¢ Report Generation  ‚îÇ                     ‚îÇ
‚îÇ                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                     ‚îÇ
‚îÇ                               ‚îÇ                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                ‚îÇ
                                ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    OUTPUT & DISTRIBUTION LAYER                   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Web Dashboard  ‚îÇ  Telegram Bot  ‚îÇ  Email Alerts  ‚îÇ  API       ‚îÇ
‚îÇ  (Next.js)      ‚îÇ  (Real-time)   ‚îÇ  (Daily/Event) ‚îÇ  (REST)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## 1. DATA INGESTION - Thu Th·∫≠p D·ªØ Li·ªáu

### 1.1 Ngu·ªìn Ch√≠nh Th·ªëng (Official Sources)

**A. RSS Feeds & News APIs:**
```javascript
const officialSources = {
  vneconomy: {
    rss: 'https://vneconomy.vn/rss/chung-khoan.rss',
    priority: 'high',
    reliability: 0.9
  },
  cafef: {
    rss: 'https://cafef.vn/chung-khoan.rss',
    priority: 'high',
    reliability: 0.85
  },
  vietstock: {
    api: 'https://api.vietstock.vn/finance/...',
    priority: 'medium',
    reliability: 0.8
  },
  ndh: {
    rss: 'https://ndh.vn/chung-khoan.rss',
    priority: 'medium',
    reliability: 0.75
  }
}
```

**B. Exchange Data (HSX/HNX/UPCOM):**
- D·ªØ li·ªáu giao d·ªãch real-time t·ª´ HSX API
- Th√¥ng tin c√¥ng b·ªë th√¥ng tin t·ª´ HNX
- B√°o c√°o t√†i ch√≠nh t·ª´ UPCOM

### 1.2 D·ªØ Li·ªáu S·ªë (Market Data APIs)

**A. Financial Data Providers:**
```python
# V√≠ d·ª• integration v·ªõi vnstock
import vnstock
from vnstock import stock_historical_data

def get_technical_data(symbol, start_date, end_date):
    """
    L·∫•y d·ªØ li·ªáu l·ªãch s·ª≠ gi√° c·ªï phi·∫øu
    """
    data = stock_historical_data(
        symbol=symbol,
        start_date=start_date,
        end_date=end_date,
        resolution='1D'
    )
    return data

# Ho·∫∑c s·ª≠ d·ª•ng FiinGroup API (tr·∫£ ph√≠)
FIIN_API_CONFIG = {
    'endpoint': 'https://api.fiingroup.vn/StockInfo',
    'headers': {
        'Authorization': 'Bearer YOUR_TOKEN',
        'Content-Type': 'application/json'
    }
}
```

**B. C√°c ch·ªâ s·ªë c·∫ßn thu th·∫≠p:**
- OHLC (Open, High, Low, Close)
- Volume (Kh·ªëi l∆∞·ª£ng giao d·ªãch)
- P/E, P/B, EPS, ROE, ROA
- Market Cap (V·ªën h√≥a)
- Foreign Ownership (Room ngo·∫°i)
- Insider Trading Data

### 1.3 Ngu·ªìn C·ªông ƒê·ªìng (Social Sentiment)

**A. Facebook Groups:**
```javascript
// S·ª≠ d·ª•ng Apify ho·∫∑c Bright Data ƒë·ªÉ scrape
const fbGroups = [
  'Ch·ª©ng kho√°n Vi·ªát Nam',
  'ƒê·∫ßu t∆∞ ch·ª©ng kho√°n th√¥ng minh',
  'Ph√¢n t√≠ch k·ªπ thu·∫≠t ch·ª©ng kho√°n VN'
]

// Scraping flow
async function scrapeFacebookGroup(groupId) {
  // S·ª≠ d·ª•ng Apify Actor
  const run = await apifyClient.actor("apify/facebook-pages-scraper").call({
    startUrls: [`https://www.facebook.com/groups/${groupId}`],
    maxPosts: 50
  });
  
  return run.dataset.items;
}
```

**B. Telegram Channels:**
```python
from telethon import TelegramClient

# Channels ph·ªï bi·∫øn
TELEGRAM_CHANNELS = [
    '@chungkhoanvietnam',
    '@stockvietnam',
    '@vnstock_analysis'
]

async def scrape_telegram_messages(channel, limit=100):
    """
    L·∫•y tin nh·∫Øn t·ª´ Telegram channel
    """
    client = TelegramClient('session', API_ID, API_HASH)
    await client.start()
    
    messages = []
    async for message in client.iter_messages(channel, limit=limit):
        messages.append({
            'text': message.text,
            'date': message.date,
            'views': message.views
        })
    
    return messages
```

**C. Zalo Groups (Kh√≥ khƒÉn h∆°n):**
- Y√™u c·∫ßu Zalo API access (h·∫°n ch·∫ø)
- C√≥ th·ªÉ c·∫ßn manual monitoring ho·∫∑c bot member
- Alternative: S·ª≠ d·ª•ng ng∆∞·ªùi d√πng th·∫≠t forward tin quan tr·ªçng

---

## 2. n8n WORKFLOW - Quy Tr√¨nh T·ª± ƒê·ªông

### 2.1 Main Orchestration Workflow

```json
{
  "name": "Daily Stock Market Analysis",
  "nodes": [
    {
      "type": "n8n-nodes-base.cron",
      "name": "Daily Trigger",
      "parameters": {
        "triggerTimes": {
          "hour": 8,
          "minute": 0
        }
      }
    },
    {
      "type": "n8n-nodes-base.httpRequest",
      "name": "Scrape RSS Feeds",
      "parameters": {
        "url": "={{$node['Get Sources'].json['rss_url']}}",
        "method": "GET"
      }
    },
    {
      "type": "n8n-nodes-base.code",
      "name": "Parse & Filter News",
      "parameters": {
        "jsCode": `
          // L·ªçc b·ªè tin r√°c, spam "l√πa g√†"
          const spamKeywords = ['khuy·∫øn m·∫°i', 'ƒëƒÉng k√Ω ngay', 'c∆° h·ªôi v√†ng'];
          const items = $input.all();
          
          return items.filter(item => {
            const text = item.json.title + ' ' + item.json.description;
            return !spamKeywords.some(keyword => 
              text.toLowerCase().includes(keyword)
            );
          });
        `
      }
    },
    {
      "type": "n8n-nodes-base.aws",
      "name": "Save to S3 Raw",
      "parameters": {
        "bucket": "vnstock-data",
        "key": "raw-data/news/{{$now.format('YYYY-MM-DD')}}.json",
        "data": "={{$json}}"
      }
    },
    {
      "type": "n8n-nodes-base.httpRequest",
      "name": "Call Sentiment Agent",
      "parameters": {
        "url": "http://agent-service:8000/analyze/sentiment",
        "method": "POST",
        "body": "={{$json}}"
      }
    },
    {
      "type": "n8n-nodes-base.httpRequest",
      "name": "Get Market Data",
      "parameters": {
        "url": "https://api.vietstock.vn/finance/stockprice",
        "authentication": "genericCredentialType"
      }
    },
    {
      "type": "n8n-nodes-base.httpRequest",
      "name": "Call Technical Agent",
      "parameters": {
        "url": "http://agent-service:8000/analyze/technical",
        "method": "POST"
      }
    },
    {
      "type": "n8n-nodes-base.httpRequest",
      "name": "Master Agent Synthesis",
      "parameters": {
        "url": "http://agent-service:8000/synthesize",
        "method": "POST",
        "body": {
          "sentiment": "={{$node['Call Sentiment Agent'].json}}",
          "technical": "={{$node['Call Technical Agent'].json}}"
        }
      }
    },
    {
      "type": "n8n-nodes-base.aws",
      "name": "Save Final Report",
      "parameters": {
        "bucket": "vnstock-data",
        "key": "reports/daily/{{$now.format('YYYY-MM-DD')}}.json"
      }
    },
    {
      "type": "n8n-nodes-base.telegram",
      "name": "Send to Telegram",
      "parameters": {
        "chatId": "@vnstock_alerts",
        "text": "={{$json['summary']}}"
      }
    }
  ]
}
```

### 2.2 Hot Stocks Detection Workflow

```javascript
// Workflow ph√°t hi·ªán c·ªï phi·∫øu "hot" trong ng√†y
async function detectHotStocks(newsData, socialData, marketData) {
  const stockMentions = {};
  
  // ƒê·∫øm s·ªë l·∫ßn xu·∫•t hi·ªán m·ªói m√£
  [...newsData, ...socialData].forEach(item => {
    const symbols = extractStockSymbols(item.text);
    symbols.forEach(symbol => {
      stockMentions[symbol] = (stockMentions[symbol] || 0) + 1;
    });
  });
  
  // L·ªçc top 10 m√£ ƒë∆∞·ª£c nh·∫Øc ƒë·∫øn nhi·ªÅu nh·∫•t
  const hotStocks = Object.entries(stockMentions)
    .sort((a, b) => b[1] - a[1])
    .slice(0, 10)
    .map(([symbol, count]) => ({
      symbol,
      mentions: count,
      priceChange: marketData[symbol]?.priceChange || 0,
      volume: marketData[symbol]?.volume || 0
    }));
  
  return hotStocks;
}

function extractStockSymbols(text) {
  // Regex ƒë·ªÉ t√¨m m√£ ch·ª©ng kho√°n VN (3 ch·ªØ c√°i in hoa)
  const regex = /\b[A-Z]{3}\b/g;
  const matches = text.match(regex) || [];
  
  // Filter ra c√°c m√£ th·∫≠t (so v·ªõi danh s√°ch m√£ ni√™m y·∫øt)
  return matches.filter(symbol => VALID_SYMBOLS.includes(symbol));
}
```

---

## 3. AI AGENT ARCHITECTURE - Ki·∫øn Tr√∫c Agents

### 3.1 Technical Analysis Agent

```python
import pandas as pd
import ta

class TechnicalAgent:
    """
    Agent ph√¢n t√≠ch k·ªπ thu·∫≠t
    """
    
    def __init__(self, data: pd.DataFrame):
        self.data = data
        self.indicators = {}
    
    def calculate_indicators(self):
        """
        T√≠nh to√°n c√°c ch·ªâ b√°o k·ªπ thu·∫≠t
        """
        df = self.data
        
        # RSI (Relative Strength Index)
        self.indicators['rsi'] = ta.momentum.RSIIndicator(
            close=df['close'], 
            window=14
        ).rsi()
        
        # MACD
        macd = ta.trend.MACD(close=df['close'])
        self.indicators['macd'] = macd.macd()
        self.indicators['macd_signal'] = macd.macd_signal()
        
        # Bollinger Bands
        bb = ta.volatility.BollingerBands(close=df['close'])
        self.indicators['bb_upper'] = bb.bollinger_hband()
        self.indicators['bb_lower'] = bb.bollinger_lband()
        self.indicators['bb_middle'] = bb.bollinger_mavg()
        
        # Moving Averages
        self.indicators['sma_20'] = ta.trend.SMAIndicator(
            close=df['close'], 
            window=20
        ).sma_indicator()
        
        self.indicators['ema_50'] = ta.trend.EMAIndicator(
            close=df['close'],
            window=50
        ).ema_indicator()
        
        return self.indicators
    
    def generate_signals(self):
        """
        T·∫°o t√≠n hi·ªáu mua/b√°n d·ª±a tr√™n ch·ªâ b√°o
        """
        signals = {
            'recommendation': 'HOLD',
            'confidence': 0.5,
            'reasons': []
        }
        
        current_rsi = self.indicators['rsi'].iloc[-1]
        current_price = self.data['close'].iloc[-1]
        sma_20 = self.indicators['sma_20'].iloc[-1]
        
        # RSI signals
        if current_rsi < 30:
            signals['recommendation'] = 'BUY'
            signals['confidence'] += 0.2
            signals['reasons'].append('RSI oversold (<30)')
        elif current_rsi > 70:
            signals['recommendation'] = 'SELL'
            signals['confidence'] += 0.2
            signals['reasons'].append('RSI overbought (>70)')
        
        # Price vs SMA
        if current_price > sma_20:
            signals['confidence'] += 0.1
            signals['reasons'].append('Price above SMA20 (bullish)')
        else:
            signals['confidence'] -= 0.1
            signals['reasons'].append('Price below SMA20 (bearish)')
        
        # MACD crossover
        macd_current = self.indicators['macd'].iloc[-1]
        macd_signal = self.indicators['macd_signal'].iloc[-1]
        
        if macd_current > macd_signal:
            signals['confidence'] += 0.15
            signals['reasons'].append('MACD bullish crossover')
        
        return signals
```

### 3.2 Sentiment Analysis Agent

```python
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch

class SentimentAgent:
    """
    Agent ph√¢n t√≠ch t√¢m l√Ω th·ªã tr∆∞·ªùng t·ª´ tin t·ª©c v√† MXH
    """
    
    def __init__(self, model_name='vinai/phobert-base'):
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        self.model = AutoModelForSequenceClassification.from_pretrained(
            model_name,
            num_labels=3  # Positive, Neutral, Negative
        )
        
        # T·ª´ ƒëi·ªÉn t·ª´ l√≥ng ch·ª©ng kho√°n VN
        self.slang_dict = {
            'c√¢y th√¥ng': 'bullish_pattern',
            'm√∫a b√™n trƒÉng': 'price_manipulation',
            'fomo': 'fear_of_missing_out',
            'sideway': 'sideways_trend',
            'breakout': 'price_breakout',
            'h·ªët': 'buy_opportunity',
            'ch·ªët l·ªùi': 'take_profit',
            'c·∫Øt l·ªó': 'stop_loss',
            'l√πa g√†': 'pump_and_dump',
            'con t√©p': 'small_investor'
        }
    
    def preprocess_text(self, text: str) -> str:
        """
        Chu·∫©n h√≥a text, thay th·∫ø slang
        """
        text_lower = text.lower()
        
        for slang, meaning in self.slang_dict.items():
            text_lower = text_lower.replace(slang, f' {meaning} ')
        
        return text_lower
    
    def analyze_sentiment(self, text: str) -> dict:
        """
        Ph√¢n t√≠ch c·∫£m x√∫c c·ªßa m·ªôt ƒëo·∫°n text
        """
        processed_text = self.preprocess_text(text)
        inputs = self.tokenizer(
            processed_text,
            return_tensors='pt',
            truncation=True,
            max_length=256
        )
        
        with torch.no_grad():
            outputs = self.model(**inputs)
            logits = outputs.logits
            probabilities = torch.softmax(logits, dim=1)
        
        sentiment_map = {0: 'negative', 1: 'neutral', 2: 'positive'}
        predicted_class = torch.argmax(probabilities).item()
        
        return {
            'sentiment': sentiment_map[predicted_class],
            'confidence': probabilities[0][predicted_class].item(),
            'scores': {
                'negative': probabilities[0][0].item(),
                'neutral': probabilities[0][1].item(),
                'positive': probabilities[0][2].item()
            }
        }
    
    def analyze_batch(self, texts: list) -> dict:
        """
        Ph√¢n t√≠ch sentiment cho nhi·ªÅu text (tin t·ª©c, b√†i ƒëƒÉng MXH)
        """
        results = [self.analyze_sentiment(text) for text in texts]
        
        # T√≠nh ƒëi·ªÉm trung b√¨nh
        avg_sentiment = {
            'positive_ratio': sum(1 for r in results if r['sentiment'] == 'positive') / len(results),
            'negative_ratio': sum(1 for r in results if r['sentiment'] == 'negative') / len(results),
            'neutral_ratio': sum(1 for r in results if r['sentiment'] == 'neutral') / len(results),
            'overall_score': sum(r['scores']['positive'] - r['scores']['negative'] for r in results) / len(results)
        }
        
        return {
            'individual_results': results,
            'aggregate': avg_sentiment
        }
    
    def detect_rumors(self, social_texts: list, official_texts: list) -> dict:
        """
        So s√°nh tin t·ª´ MXH v·ªõi tin ch√≠nh th·ªëng ƒë·ªÉ ph√°t hi·ªán tin ƒë·ªìn
        """
        # Extract entities (stock symbols) t·ª´ social media
        social_entities = self._extract_entities(social_texts)
        official_entities = self._extract_entities(official_texts)
        
        # T√¨m c√°c m√£ ch·ªâ xu·∫•t hi·ªán tr√™n MXH (nghi ng·ªù tin ƒë·ªìn)
        rumor_candidates = set(social_entities.keys()) - set(official_entities.keys())
        
        rumors = []
        for symbol in rumor_candidates:
            rumors.append({
                'symbol': symbol,
                'mentions': social_entities[symbol],
                'risk_level': 'HIGH' if social_entities[symbol] > 10 else 'MEDIUM',
                'warning': 'Ch∆∞a c√≥ x√°c nh·∫≠n t·ª´ ngu·ªìn ch√≠nh th·ªëng'
            })
        
        return {
            'detected_rumors': rumors,
            'verified_news': list(official_entities.keys())
        }
    
    def _extract_entities(self, texts: list) -> dict:
        """
        Tr√≠ch xu·∫•t m√£ ch·ª©ng kho√°n t·ª´ text
        """
        import re
        entities = {}
        
        for text in texts:
            symbols = re.findall(r'\b[A-Z]{3}\b', text)
            for symbol in symbols:
                entities[symbol] = entities.get(symbol, 0) + 1
        
        return entities
```

### 3.3 Forecast Agent

```python
import numpy as np
from sklearn.ensemble import RandomForestClassifier

class ForecastAgent:
    """
    Agent d·ª± b√°o xu h∆∞·ªõng t·ªïng h·ª£p
    """
    
    def __init__(self):
        self.model = RandomForestClassifier(n_estimators=100)
        self.is_trained = False
    
    def synthesize_analysis(
        self, 
        technical_signals: dict, 
        sentiment_data: dict,
        market_context: dict
    ) -> dict:
        """
        T·ªïng h·ª£p k·∫øt qu·∫£ t·ª´ Technical Agent v√† Sentiment Agent
        """
        # T√≠nh ƒëi·ªÉm t·ªïng h·ª£p
        technical_score = self._score_technical(technical_signals)
        sentiment_score = self._score_sentiment(sentiment_data)
        market_score = self._score_market(market_context)
        
        # Weighted average
        final_score = (
            technical_score * 0.4 +
            sentiment_score * 0.3 +
            market_score * 0.3
        )
        
        # ƒê∆∞a ra khuy·∫øn ngh·ªã
        recommendation = self._generate_recommendation(
            final_score,
            technical_signals,
            sentiment_data
        )
        
        return {
            'recommendation': recommendation['action'],
            'confidence': recommendation['confidence'],
            'risk_level': self._calculate_risk(technical_signals, sentiment_data),
            'target_price': self._estimate_target_price(technical_signals),
            'reasoning': recommendation['reasons'],
            'scores': {
                'technical': technical_score,
                'sentiment': sentiment_score,
                'market': market_score,
                'final': final_score
            }
        }
    
    def _score_technical(self, signals: dict) -> float:
        """Chuy·ªÉn technical signals th√†nh ƒëi·ªÉm s·ªë 0-1"""
        score = 0.5  # baseline
        
        if signals['recommendation'] == 'BUY':
            score += signals['confidence'] * 0.5
        elif signals['recommendation'] == 'SELL':
            score -= signals['confidence'] * 0.5
        
        return max(0, min(1, score))
    
    def _score_sentiment(self, data: dict) -> float:
        """Chuy·ªÉn sentiment data th√†nh ƒëi·ªÉm s·ªë 0-1"""
        if 'aggregate' in data:
            return (data['aggregate']['overall_score'] + 1) / 2  # Normalize t·ª´ [-1,1] sang [0,1]
        return 0.5
    
    def _score_market(self, context: dict) -> float:
        """ƒê√°nh gi√° b·ªëi c·∫£nh th·ªã tr∆∞·ªùng chung"""
        score = 0.5
        
        # VN-Index trend
        if context.get('vnindex_change', 0) > 0:
            score += 0.2
        elif context.get('vnindex_change', 0) < -1:
            score -= 0.2
        
        # Volume
        if context.get('volume_ratio', 1) > 1.2:  # Volume tƒÉng 20%
            score += 0.1
        
        # Foreign flow
        if context.get('foreign_net_value', 0) > 0:
            score += 0.15
        
        return max(0, min(1, score))
    
    def _generate_recommendation(
        self, 
        final_score: float,
        technical: dict,
        sentiment: dict
    ) -> dict:
        """
        T·∫°o khuy·∫øn ngh·ªã cu·ªëi c√πng
        """
        reasons = []
        
        if final_score >= 0.7:
            action = 'STRONG BUY'
            confidence = final_score
            reasons.append('T√≠n hi·ªáu k·ªπ thu·∫≠t t√≠ch c·ª±c')
            reasons.append('Sentiment th·ªã tr∆∞·ªùng l·∫°c quan')
        elif final_score >= 0.55:
            action = 'BUY'
            confidence = final_score
            reasons.append('Xu h∆∞·ªõng tƒÉng ng·∫Øn h·∫°n')
        elif final_score >= 0.45:
            action = 'HOLD'
            confidence = 0.6
            reasons.append('Th·ªã tr∆∞·ªùng sideway, ch·ªù t√≠n hi·ªáu r√µ h∆°n')
        elif final_score >= 0.3:
            action = 'SELL'
            confidence = 1 - final_score
            reasons.append('√Åp l·ª±c b√°n tƒÉng')
        else:
            action = 'STRONG SELL'
            confidence = 1 - final_score
            reasons.append('T√≠n hi·ªáu k·ªπ thu·∫≠t ti√™u c·ª±c m·∫°nh')
        
        # Th√™m c·∫£nh b√°o r·ªßi ro
        if sentiment.get('detected_rumors'):
            reasons.append('‚ö†Ô∏è C·∫¢NH B√ÅO: Ph√°t hi·ªán tin ƒë·ªìn ch∆∞a x√°c minh')
        
        return {
            'action': action,
            'confidence': confidence,
            'reasons': reasons
        }
    
    def _calculate_risk(self, technical: dict, sentiment: dict) -> str:
        """ƒê√°nh gi√° m·ª©c ƒë·ªô r·ªßi ro"""
        risk_score = 0
        
        # Volatility cao = r·ªßi ro cao
        if technical.get('volatility', 0) > 3:
            risk_score += 2
        
        # Sentiment ti√™u c·ª±c
        if sentiment.get('aggregate', {}).get('negative_ratio', 0) > 0.5:
            risk_score += 2
        
        # C√≥ tin ƒë·ªìn
        if sentiment.get('detected_rumors'):
            risk_score += 3
        
        if risk_score >= 5:
            return 'HIGH'
        elif risk_score >= 3:
            return 'MEDIUM'
        else:
            return 'LOW'
    
    def _estimate_target_price(self, technical: dict) -> dict:
        """∆Ø·ªõc t√≠nh gi√° m·ª•c ti√™u"""
        current_price = technical.get('current_price', 0)
        bb_upper = technical.get('bb_upper', current_price * 1.05)
        bb_lower = technical.get('bb_lower', current_price * 0.95)
        
        return {
            'short_term_target': bb_upper,
            'support_level': bb_lower,
            'expected_return': ((bb_upper - current_price) / current_price) * 100
        }
```

### 3.4 Master Orchestrator Agent

```python
class MasterAgent:
    """
    Agent t·ªïng ch·ªâ huy, ƒëi·ªÅu ph·ªëi c√°c agents kh√°c
    """
    
    def __init__(self):
        self.technical_agent = TechnicalAgent
        self.sentiment_agent = SentimentAgent()
        self.forecast_agent = ForecastAgent()
    
    async def analyze_stock(self, symbol: str, date: str) -> dict:
        """
        Ph√¢n t√≠ch to√†n di·ªán m·ªôt m√£ c·ªï phi·∫øu
        """
        # 1. Thu th·∫≠p d·ªØ li·ªáu
        market_data = await self._fetch_market_data(symbol, date)
        news_data = await self._fetch_news_data(symbol, date)
        social_data = await self._fetch_social_data(symbol, date)
        
        # 2. Ph√¢n t√≠ch k·ªπ thu·∫≠t
        tech_agent = self.technical_agent(market_data)
        tech_agent.calculate_indicators()
        technical_signals = tech_agent.generate_signals()
        
        # 3. Ph√¢n t√≠ch t√¢m l√Ω
        sentiment_results = self.sentiment_agent.analyze_batch(
            news_data + social_data
        )
        
        # 4. Ph√°t hi·ªán tin ƒë·ªìn
        rumor_check = self.sentiment_agent.detect_rumors(
            social_data, 
            news_data
        )
        sentiment_results['detected_rumors'] = rumor_check['detected_rumors']
        
        # 5. D·ª± b√°o t·ªïng h·ª£p
        market_context = await self._get_market_context()
        forecast = self.forecast_agent.synthesize_analysis(
            technical_signals,
            sentiment_results,
            market_context
        )
        
        # 6. T·ªïng h·ª£p b√°o c√°o
        report = {
            'symbol': symbol,
            'date': date,
            'analysis': {
                'technical': technical_signals,
                'sentiment': sentiment_results,
                'forecast': forecast
            },
            'recommendation': forecast['recommendation'],
            'confidence': forecast['confidence'],
            'risk_level': forecast['risk_level'],
            'key_insights': self._extract_insights(
                technical_signals, 
                sentiment_results, 
                forecast
            )
        }
        
        return report
    
    async def generate_daily_report(self, date: str) -> dict:
        """
        T·∫°o b√°o c√°o t·ªïng h·ª£p th·ªã tr∆∞·ªùng h√†ng ng√†y
        """
        # Ph√°t hi·ªán hot stocks
        hot_stocks = await self._detect_hot_stocks(date)
        
        # Ph√¢n t√≠ch t·ª´ng m√£ hot
        analyses = []
        for stock in hot_stocks[:5]:  # Top 5
            analysis = await self.analyze_stock(stock['symbol'], date)
            analyses.append(analysis)
        
        # Market overview
        market_overview = await self._get_market_overview(date)
        
        # T·∫°o b√°o c√°o
        report = {
            'date': date,
            'market_overview': market_overview,
            'hot_stocks': hot_stocks,
            'top_recommendations': self._rank_recommendations(analyses),
            'detailed_analyses': analyses,
            'alerts': self._generate_alerts(analyses)
        }
        
        return report
    
    def _extract_insights(self, technical, sentiment, forecast) -> list:
        """Tr√≠ch xu·∫•t c√°c insight quan tr·ªçng"""
        insights = []
        
        # Technical insights
        if 'RSI oversold' in str(technical.get('reasons', [])):
            insights.append('üìä RSI cho th·∫•y c·ªï phi·∫øu ƒëang ·ªü v√πng oversold')
        
        # Sentiment insights
        if sentiment.get('detected_rumors'):
            insights.append('‚ö†Ô∏è Ph√°t hi·ªán tin ƒë·ªìn tr√™n MXH, c·∫ßn th·∫≠n tr·ªçng')
        
        # Forecast insights
        if forecast['confidence'] > 0.8:
            insights.append(f"‚úÖ ƒê·ªô tin c·∫≠y cao ({forecast['confidence']:.1%})")
        
        return insights
    
    def _rank_recommendations(self, analyses: list) -> list:
        """X·∫øp h·∫°ng c√°c khuy·∫øn ngh·ªã"""
        ranked = sorted(
            analyses,
            key=lambda x: x['confidence'],
            reverse=True
        )
        
        return [
            {
                'symbol': a['symbol'],
                'recommendation': a['recommendation'],
                'confidence': a['confidence'],
                'key_reason': a['key_insights'][0] if a['key_insights'] else ''
            }
            for a in ranked
        ]
    
    def _generate_alerts(self, analyses: list) -> list:
        """T·∫°o c·∫£nh b√°o quan tr·ªçng"""
        alerts = []
        
        for analysis in analyses:
            # High risk alert
            if analysis['risk_level'] == 'HIGH':
                alerts.append({
                    'type': 'HIGH_RISK',
                    'symbol': analysis['symbol'],
                    'message': f"‚ö†Ô∏è {analysis['symbol']}: M·ª©c r·ªßi ro cao!"
                })
            
            # Strong buy/sell
            if analysis['recommendation'] in ['STRONG BUY', 'STRONG SELL']:
                alerts.append({
                    'type': 'STRONG_SIGNAL',
                    'symbol': analysis['symbol'],
                    'message': f"üîî {analysis['symbol']}: {analysis['recommendation']}"
                })
            
            # Rumor detection
            if analysis['analysis']['sentiment'].get('detected_rumors'):
                alerts.append({
                    'type': 'RUMOR',
                    'symbol': analysis['symbol'],
                    'message': f"üö® {analysis['symbol']}: Ph√°t hi·ªán tin ƒë·ªìn"
                })
        
        return alerts
```

---

## 4. OUTPUT & DISTRIBUTION - Xu·∫•t B√°o C√°o

### 4.1 Report Generator

```python
from datetime import datetime
import json

class ReportGenerator:
    """
    T·∫°o b√°o c√°o d∆∞·ªõi nhi·ªÅu ƒë·ªãnh d·∫°ng
    """
    
    def generate_markdown_report(self, data: dict) -> str:
        """
        T·∫°o b√°o c√°o Markdown
        """
        md = f"""# B√°o C√°o Ph√¢n T√≠ch Th·ªã Tr∆∞·ªùng Ch·ª©ng Kho√°n
**Ng√†y:** {data['date']}

## üìä T·ªïng Quan Th·ªã Tr∆∞·ªùng

- **VN-Index:** {data['market_overview']['vnindex']} ({data['market_overview']['vnindex_change']:+.2f}%)
- **Thanh kho·∫£n:** {data['market_overview']['total_volume']} t·ª∑ ƒë·ªìng
- **Kh·ªëi ngo·∫°i:** {data['market_overview']['foreign_net_value']:+.0f} t·ª∑ ƒë·ªìng

---

## üî• Top C·ªï Phi·∫øu Hot Trong Ng√†y

"""
        for stock in data['hot_stocks'][:5]:
            md += f"### {stock['symbol']}\n"
            md += f"- **Mentions:** {stock['mentions']}\n"
            md += f"- **Gi√°:** {stock['price']:,.0f} VND ({stock['price_change']:+.2f}%)\n"
            md += f"- **Khuy·∫øn ngh·ªã:** {stock['recommendation']}\n"
            md += f"- **ƒê·ªô tin c·∫≠y:** {stock['confidence']:.1%}\n\n"
        
        md += "---\n\n## üéØ Ph√¢n T√≠ch Chi Ti·∫øt\n\n"
        
        for analysis in data['detailed_analyses']:
            md += self._format_stock_analysis(analysis)
        
        md += "---\n\n## ‚ö†Ô∏è C·∫£nh B√°o\n\n"
        for alert in data['alerts']:
            md += f"- {alert['message']}\n"
        
        md += f"\n---\n\n*B√°o c√°o ƒë∆∞·ª£c t·∫°o t·ª± ƒë·ªông b·ªüi AI Agent System*\n"
        md += f"*L∆∞u √Ω: ƒê√¢y ch·ªâ l√† th√¥ng tin tham kh·∫£o, kh√¥ng ph·∫£i l·ªùi khuy√™n ƒë·∫ßu t∆∞*\n"
        
        return md
    
    def _format_stock_analysis(self, analysis: dict) -> str:
        """Format ph√¢n t√≠ch m·ªôt m√£"""
        md = f"### {analysis['symbol']}\n\n"
        
        md += f"**Khuy·∫øn ngh·ªã:** {analysis['recommendation']} "
        md += f"(Confidence: {analysis['confidence']:.1%})\n\n"
        
        md += f"**M·ª©c r·ªßi ro:** {analysis['risk_level']}\n\n"
        
        md += "**Key Insights:**\n"
        for insight in analysis['key_insights']:
            md += f"- {insight}\n"
        
        md += "\n"
        
        return md
    
    def generate_json_report(self, data: dict) -> str:
        """Xu·∫•t b√°o c√°o JSON cho API"""
        return json.dumps(data, ensure_ascii=False, indent=2)
    
    def generate_html_report(self, data: dict) -> str:
        """T·∫°o b√°o c√°o HTML ƒë·∫πp"""
        html = f"""
<!DOCTYPE html>
<html lang="vi">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>B√°o C√°o Ph√¢n T√≠ch Th·ªã Tr∆∞·ªùng - {data['date']}</title>
    <style>
        body {{
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background: #f5f5f5;
        }}
        .header {{
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 30px;
            border-radius: 10px;
            margin-bottom: 30px;
        }}
        .stock-card {{
            background: white;
            padding: 20px;
            margin: 15px 0;
            border-radius: 8px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }}
        .recommendation {{
            display: inline-block;
            padding: 5px 15px;
            border-radius: 20px;
            font-weight: bold;
        }}
        .buy {{ background: #4caf50; color: white; }}
        .sell {{ background: #f44336; color: white; }}
        .hold {{ background: #ff9800; color: white; }}
        .risk-high {{ color: #f44336; }}
        .risk-medium {{ color: #ff9800; }}
        .risk-low {{ color: #4caf50; }}
    </style>
</head>
<body>
    <div class="header">
        <h1>üìä B√°o C√°o Ph√¢n T√≠ch Th·ªã Tr∆∞·ªùng</h1>
        <p>Ng√†y: {data['date']}</p>
    </div>
    
    <div class="market-overview">
        <h2>T·ªïng Quan Th·ªã Tr∆∞·ªùng</h2>
        <p>VN-Index: <strong>{data['market_overview']['vnindex']}</strong> 
           ({data['market_overview']['vnindex_change']:+.2f}%)</p>
    </div>
    
    <h2>üî• Top C·ªï Phi·∫øu</h2>
"""
        
        for analysis in data['detailed_analyses']:
            rec_class = analysis['recommendation'].lower().replace(' ', '-')
            risk_class = f"risk-{analysis['risk_level'].lower()}"
            
            html += f"""
    <div class="stock-card">
        <h3>{analysis['symbol']}</h3>
        <span class="recommendation {rec_class}">{analysis['recommendation']}</span>
        <p>ƒê·ªô tin c·∫≠y: {analysis['confidence']:.1%}</p>
        <p class="{risk_class}">R·ªßi ro: {analysis['risk_level']}</p>
        <ul>
"""
            for insight in analysis['key_insights']:
                html += f"            <li>{insight}</li>\n"
            
            html += """        </ul>
    </div>
"""
        
        html += """
    <footer style="text-align: center; margin-top: 50px; color: #666;">
        <p><em>B√°o c√°o ƒë∆∞·ª£c t·∫°o t·ª± ƒë·ªông b·ªüi AI Agent System</em></p>
        <p><small>L∆∞u √Ω: ƒê√¢y ch·ªâ l√† th√¥ng tin tham kh·∫£o, kh√¥ng ph·∫£i l·ªùi khuy√™n ƒë·∫ßu t∆∞</small></p>
    </footer>
</body>
</html>
"""
        return html
```

### 4.2 Telegram Bot Integration

```python
from telegram import Bot, Update
from telegram.ext import Application, CommandHandler, ContextTypes

class TelegramDistributor:
    """
    G·ª≠i c·∫£nh b√°o v√† b√°o c√°o qua Telegram
    """
    
    def __init__(self, bot_token: str):
        self.bot = Bot(token=bot_token)
        self.app = Application.builder().token(bot_token).build()
        
        # Register handlers
        self.app.add_handler(CommandHandler("start", self.start_command))
        self.app.add_handler(CommandHandler("report", self.daily_report))
        self.app.add_handler(CommandHandler("alert", self.subscribe_alerts))
    
    async def start_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Welcome message"""
        await update.message.reply_text(
            "ü§ñ Ch√†o m·ª´ng ƒë·∫øn v·ªõi VN Stock Analysis Bot!\n\n"
            "Commands:\n"
            "/report - Nh·∫≠n b√°o c√°o h√†ng ng√†y\n"
            "/alert - ƒêƒÉng k√Ω nh·∫≠n c·∫£nh b√°o real-time\n"
            "/stock <symbol> - Ph√¢n t√≠ch m√£ c·ª• th·ªÉ"
        )
    
    async def send_daily_report(self, chat_id: str, report_data: dict):
        """G·ª≠i b√°o c√°o h√†ng ng√†y"""
        message = self._format_telegram_message(report_data)
        await self.bot.send_message(chat_id=chat_id, text=message, parse_mode='Markdown')
    
    async def send_alert(self, chat_id: str, alert: dict):
        """G·ª≠i c·∫£nh b√°o real-time"""
        message = f"{alert['message']}\n\n"
        message += f"Symbol: `{alert['symbol']}`\n"
        message += f"Type: {alert['type']}"
        
        await self.bot.send_message(chat_id=chat_id, text=message, parse_mode='Markdown')
    
    def _format_telegram_message(self, data: dict) -> str:
        """Format message cho Telegram"""
        msg = f"üìä *B√°o C√°o Th·ªã Tr∆∞·ªùng - {data['date']}*\n\n"
        
        msg += f"*VN-Index:* {data['market_overview']['vnindex']} "
        msg += f"({data['market_overview']['vnindex_change']:+.2f}%)\n\n"
        
        msg += "*üî• Top Khuy·∫øn Ngh·ªã:*\n"
        for rec in data['top_recommendations'][:3]:
            msg += f"‚Ä¢ `{rec['symbol']}` - {rec['recommendation']} "
            msg += f"({rec['confidence']:.0%})\n"
        
        msg += "\n_Chi ti·∫øt: /report_"
        
        return msg
```

---

## 5. DEPLOYMENT & INFRASTRUCTURE

### 5.1 Docker Compose Setup

```yaml
version: '3.8'

services:
  n8n:
    image: n8nio/n8n
    container_name: vnstock-n8n
    ports:
      - "5678:5678"
    environment:
      - N8N_BASIC_AUTH_ACTIVE=true
      - N8N_BASIC_AUTH_USER=admin
      - N8N_BASIC_AUTH_PASSWORD=${N8N_PASSWORD}
      - WEBHOOK_URL=https://your-domain.com/
    volumes:
      - n8n_data:/home/node/.n8n
    networks:
      - vnstock-net

  agent-service:
    build: ./agent-service
    container_name: vnstock-agents
    ports:
      - "8000:8000"
    environment:
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_KEY}
      - S3_BUCKET=vnstock-data
    volumes:
      - ./models:/app/models
    networks:
      - vnstock-net
    depends_on:
      - postgres
      - redis

  postgres:
    image: postgres:15
    container_name: vnstock-db
    environment:
      - POSTGRES_DB=vnstock
      - POSTGRES_USER=admin
      - POSTGRES_PASSWORD=${DB_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - vnstock-net

  redis:
    image: redis:7-alpine
    container_name: vnstock-cache
    ports:
      - "6379:6379"
    networks:
      - vnstock-net

  web-dashboard:
    build: ./web-dashboard
    container_name: vnstock-web
    ports:
      - "3000:3000"
    environment:
      - API_URL=http://agent-service:8000
    networks:
      - vnstock-net

volumes:
  n8n_data:
  postgres_data:

networks:
  vnstock-net:
    driver: bridge
```

### 5.2 AWS S3 Bucket Structure

```
vnstock-data/
‚îú‚îÄ‚îÄ raw-data/
‚îÇ   ‚îú‚îÄ‚îÄ news/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 2026-01-28/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ vneconomy.json
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cafef.json
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ vietstock.json
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îú‚îÄ‚îÄ market-data/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 2026-01-28/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ VNM.json
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ HPG.json
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îî‚îÄ‚îÄ social/
‚îÇ       ‚îú‚îÄ‚îÄ 2026-01-28/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ facebook.json
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ telegram.json
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ       ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ processed/
‚îÇ   ‚îú‚îÄ‚îÄ sentiment/
‚îÇ   ‚îú‚îÄ‚îÄ technical/
‚îÇ   ‚îî‚îÄ‚îÄ combined/
‚îî‚îÄ‚îÄ reports/
    ‚îú‚îÄ‚îÄ daily/
    ‚îÇ   ‚îú‚îÄ‚îÄ 2026-01-28.json
    ‚îÇ   ‚îú‚îÄ‚îÄ 2026-01-28.md
    ‚îÇ   ‚îî‚îÄ‚îÄ 2026-01-28.html
    ‚îú‚îÄ‚îÄ weekly/
    ‚îî‚îÄ‚îÄ alerts/
```

---

## 6. L∆ØU √ù QUAN TR·ªåNG & BEST PRACTICES

### 6.1 ƒê·∫∑c Th√π Ng√¥n Ng·ªØ Vi·ªát

```python
# T·ª´ ƒëi·ªÉn slang ch·ª©ng kho√°n VN (m·ªü r·ªông)
STOCK_SLANG_VIETNAMESE = {
    # M√¥ t·∫£ xu h∆∞·ªõng
    'c√¢y th√¥ng': 'M√¥ h√¨nh n·∫øn tƒÉng m·∫°nh',
    'c√¢y s√∫ng': 'M√¥ h√¨nh n·∫øn gi·∫£m m·∫°nh',
    'm√∫a b√™n trƒÉng': 'Thao t√∫ng gi√°',
    'sideway': 'Di chuy·ªÉn ngang',
    'breakout': 'V∆∞·ª£t ng∆∞·ª°ng kh√°ng c·ª±',
    'breakdown': 'Th·ªßng ng∆∞·ª°ng h·ªó tr·ª£',
    
    # H√†nh vi nh√† ƒë·∫ßu t∆∞
    'fomo': 'S·ª£ b·ªè l·ª° c∆° h·ªôi',
    'panic sell': 'B√°n th√°o ho·∫£ng lo·∫°n',
    'h·ªët': 'Mua v√†o',
    '√¥m': 'Gi·ªØ c·ªï phi·∫øu l√¢u d√†i',
    'ch·ªët l·ªùi': 'B√°n ƒë·ªÉ ch·ªët l√£i',
    'c·∫Øt l·ªó': 'B√°n ch·∫•p nh·∫≠n l·ªó',
    'all in': 'ƒê·∫ßu t∆∞ to√†n b·ªô v·ªën',
    
    # Lo·∫°i nh√† ƒë·∫ßu t∆∞
    'con t√©p': 'Nh√† ƒë·∫ßu t∆∞ nh·ªè l·∫ª',
    'c√° m·∫≠p': 'Nh√† ƒë·∫ßu t∆∞ l·ªõn',
    'l√πa g√†': 'Thao t√∫ng ƒë·ªÉ b√°n cho nh√† ƒë·∫ßu t∆∞ nh·ªè',
    'g√† m·ªù': 'Nh√† ƒë·∫ßu t∆∞ thi·∫øu kinh nghi·ªám',
    
    # Thu·∫≠t ng·ªØ k·ªπ thu·∫≠t (Viet-style)
    'l·ªách pha': 'Divergence',
    'v√πng kh√°ng c·ª±': 'Resistance zone',
    'v√πng h·ªó tr·ª£': 'Support zone',
    'ch·∫°m ƒë√°y': 'Bottom hit',
    'ƒë·ªânh': 'Peak/Top'
}
```

### 6.2 C√°c L∆∞u √ù Ph√°p L√Ω

```python
# Disclaimer template
LEGAL_DISCLAIMER = """
‚ö†Ô∏è L∆ØU √ù QUAN TR·ªåNG:

1. B√°o c√°o n√†y ƒë∆∞·ª£c t·∫°o t·ª± ƒë·ªông b·ªüi h·ªá th·ªëng AI v√† ch·ªâ mang t√≠nh ch·∫•t THAM KH·∫¢O.

2. ƒê√ÇY KH√îNG PH·∫¢I L√Ä L·ªúI KHUY√äN ƒê·∫¶U T∆Ø. Nh√† ƒë·∫ßu t∆∞ c·∫ßn t·ª± nghi√™n c·ª©u v√† 
   ch·ªãu tr√°ch nhi·ªám cho quy·∫øt ƒë·ªãnh ƒë·∫ßu t∆∞ c·ªßa m√¨nh.

3. D·ªØ li·ªáu ƒë∆∞·ª£c thu th·∫≠p t·ª´ nhi·ªÅu ngu·ªìn c√¥ng khai nh∆∞ng c√≥ th·ªÉ kh√¥ng ƒë·∫ßy ƒë·ªß 
   ho·∫∑c ch√≠nh x√°c 100%.

4. Th·ªã tr∆∞·ªùng ch·ª©ng kho√°n c√≥ r·ªßi ro cao. Ch·ªâ ƒë·∫ßu t∆∞ s·ªë ti·ªÅn b·∫°n c√≥ th·ªÉ ch·∫•p 
   nh·∫≠n m·∫•t.

5. H·ªá th·ªëng kh√¥ng ch·ªãu tr√°ch nhi·ªám cho b·∫•t k·ª≥ t·ªïn th·∫•t t√†i ch√≠nh n√†o ph√°t 
   sinh t·ª´ vi·ªác s·ª≠ d·ª•ng th√¥ng tin n√†y.

üìß Li√™n h·ªá: support@vnstock-analysis.com
"""

def add_disclaimer_to_report(report: str) -> str:
    """Th√™m disclaimer v√†o m·ªçi b√°o c√°o"""
    return report + "\n\n" + LEGAL_DISCLAIMER
```

### 6.3 Rate Limiting & API Quotas

```python
from time import sleep
import redis

class RateLimiter:
    """
    Gi·ªõi h·∫°n s·ªë l∆∞·ª£ng requests ƒë·ªÉ tr√°nh b·ªã block
    """
    
    def __init__(self, redis_client):
        self.redis = redis_client
    
    def check_limit(self, key: str, max_requests: int, window: int) -> bool:
        """
        Check if request is allowed
        
        Args:
            key: Identifier (e.g., 'vietstock_api')
            max_requests: Max requests allowed
            window: Time window in seconds
        """
        current = self.redis.get(key)
        
        if current is None:
            self.redis.setex(key, window, 1)
            return True
        
        if int(current) < max_requests:
            self.redis.incr(key)
            return True
        
        return False
    
    def wait_if_needed(self, key: str, max_requests: int, window: int):
        """Wait if rate limit exceeded"""
        while not self.check_limit(key, max_requests, window):
            print(f"Rate limit exceeded for {key}, waiting...")
            sleep(5)

# Usage
rate_limiter = RateLimiter(redis.Redis())

# Khi g·ªçi API
rate_limiter.wait_if_needed('vietstock_api', max_requests=100, window=3600)
data = fetch_from_vietstock_api()
```

### 6.4 Error Handling & Retry Logic

```python
import backoff
from requests.exceptions import RequestException

class RobustScraper:
    """
    Scraper v·ªõi retry logic v√† error handling m·∫°nh m·∫Ω
    """
    
    @backoff.on_exception(
        backoff.expo,
        RequestException,
        max_tries=5,
        max_time=300
    )
    def fetch_with_retry(self, url: str) -> dict:
        """
        Fetch data v·ªõi exponential backoff retry
        """
        try:
            response = requests.get(url, timeout=10)
            response.raise_for_status()
            return response.json()
        except RequestException as e:
            print(f"Error fetching {url}: {e}")
            raise
    
    def safe_scrape_multiple(self, urls: list) -> list:
        """
        Scrape nhi·ªÅu URL, kh√¥ng b·ªã fail to√†n b·ªô n·∫øu 1 URL l·ªói
        """
        results = []
        for url in urls:
            try:
                data = self.fetch_with_retry(url)
                results.append({'url': url, 'data': data, 'status': 'success'})
            except Exception as e:
                results.append({'url': url, 'error': str(e), 'status': 'failed'})
                continue
        
        return results
```

### 6.5 Monitoring & Alerting

```python
import logging
from datetime import datetime

class SystemMonitor:
    """
    Gi√°m s√°t ho·∫°t ƒë·ªông c·ªßa h·ªá th·ªëng
    """
    
    def __init__(self):
        self.logger = logging.getLogger('vnstock_monitor')
        self.metrics = {
            'scrapes_successful': 0,
            'scrapes_failed': 0,
            'agents_executed': 0,
            'reports_generated': 0
        }
    
    def log_scrape_result(self, source: str, success: bool):
        """Log k·∫øt qu·∫£ scraping"""
        if success:
            self.metrics['scrapes_successful'] += 1
            self.logger.info(f"‚úÖ Scraped {source} successfully")
        else:
            self.metrics['scrapes_failed'] += 1
            self.logger.error(f"‚ùå Failed to scrape {source}")
            
            # Send alert if too many failures
            if self.metrics['scrapes_failed'] > 10:
                self.send_alert("High scrape failure rate!")
    
    def send_alert(self, message: str):
        """G·ª≠i c·∫£nh b√°o qua Telegram"""
        # Implementation
        pass
    
    def get_health_status(self) -> dict:
        """Tr·∫£ v·ªÅ tr·∫°ng th√°i h·ªá th·ªëng"""
        success_rate = self.metrics['scrapes_successful'] / (
            self.metrics['scrapes_successful'] + self.metrics['scrapes_failed'] + 1
        )
        
        return {
            'status': 'healthy' if success_rate > 0.8 else 'degraded',
            'metrics': self.metrics,
            'success_rate': success_rate,
            'timestamp': datetime.now().isoformat()
        }
```

---

## 7. ROADMAP PH√ÅT TRI·ªÇN

### Phase 1: MVP (Th√°ng 1-2)
- [x] Thi·∫øt l·∫≠p infrastructure (n8n + S3 + Agents)
- [ ] Implement scraping cho 3 ngu·ªìn ch√≠nh (VnEconomy, CafeF, VietStock)
- [ ] X√¢y d·ª±ng Technical Agent c∆° b·∫£n (RSI, MACD, SMA)
- [ ] X√¢y d·ª±ng Sentiment Agent v·ªõi PhoBERT
- [ ] T·∫°o daily report Markdown/HTML
- [ ] Telegram bot c∆° b·∫£n

### Phase 2: Enhancement (Th√°ng 3-4)
- [ ] Th√™m social media scraping (Facebook, Telegram)
- [ ] N√¢ng c·∫•p Forecast Agent v·ªõi ML models
- [ ] Implement rumor detection
- [ ] Web dashboard v·ªõi real-time updates
- [ ] Email notification system
- [ ] Backtesting framework

### Phase 3: Advanced Features (Th√°ng 5-6)
- [ ] Portfolio tracking & optimization
- [ ] Customizable alerts (price, volume, news)
- [ ] Multi-timeframe analysis
- [ ] Comparative analysis (sector, peers)
- [ ] Mobile app (React Native)
- [ ] Premium subscription model

### Phase 4: Scale & Monetization (Th√°ng 7+)
- [ ] API for developers
- [ ] White-label solution cho brokers
- [ ] Advanced AI models (GPT-4, Claude)
- [ ] Market maker detection
- [ ] Institutional-grade analytics

---

## 8. K·∫æT LU·∫¨N

H·ªá th·ªëng n√†y k·∫øt h·ª£p s·ª©c m·∫°nh c·ªßa:
1. **Automation** (n8n workflows)
2. **Data Engineering** (S3, structured storage)
3. **AI/ML** (Multiple specialized agents)
4. **Real-time Distribution** (Telegram, Dashboard)

ƒê·ªÉ t·∫°o ra m·ªôt n·ªÅn t·∫£ng ph√¢n t√≠ch ch·ª©ng kho√°n VN to√†n di·ªán, gi√∫p nh√† ƒë·∫ßu t∆∞:
- Theo d√µi th·ªã tr∆∞·ªùng 24/7
- Ph√°t hi·ªán c∆° h·ªôi s·ªõm
- Tr√°nh r·ªßi ro t·ª´ tin ƒë·ªìn
- Ra quy·∫øt ƒë·ªãnh d·ª±a tr√™n d·ªØ li·ªáu

**Next Steps:**
1. Clone repository n√†y
2. Setup infrastructure (Docker Compose)
3. Configure API keys (VietStock, Telegram, AWS)
4. Deploy n8n workflows
5. Train/fine-tune AI models
6. Launch MVP!

üöÄ Happy Building!
